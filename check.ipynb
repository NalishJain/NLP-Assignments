{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nalishjain/Documents/GitHub/NLP-Assignments/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "All model checkpoint layers were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the layers of TFDistilBertForSequenceClassification were initialized from the model checkpoint at bhadresh-savani/distilbert-base-uncased-emotion.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n",
      "/Users/nalishjain/Documents/GitHub/NLP-Assignments/.venv/lib/python3.10/site-packages/transformers/pipelines/text_classification.py:105: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy as np \n",
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\",model='bhadresh-savani/distilbert-base-uncased-emotion', return_all_scores=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotion_scores(sample): \n",
    "    emotion=classifier(sample)\n",
    "    return emotion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im back to comfort me 0.8802996873855591\n",
      "i liked hasnt taken me 0.9711681008338928\n",
      "i embrace the loyal and 0.9903715252876282\n",
      "i liked song and cared 0.9935545921325684\n",
      "i held all my adoring 0.981304943561554\n",
      "i desire and warm hands 0.9769728183746338\n",
      "i loved for not wanting 0.9878526926040649\n",
      "im craving theres any other 0.9226101636886597\n"
     ]
    }
   ],
   "source": [
    "with open('gen_3_love.txt', 'r', encoding='utf-8') as file:\n",
    "    sentences = [line.strip() for line in file]\n",
    "\n",
    "# Count the number of samples with a score greater than 0.8\n",
    "count_high_score = 0\n",
    "i = 0\n",
    "indices = []\n",
    "\n",
    "for sentence in sentences:\n",
    "    scores = emotion_scores([sentence])\n",
    "    max_score = scores[2]['score']\n",
    "    print(sentence, max_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'sadness', 'score': 0.010323652066290379},\n",
       " {'label': 'joy', 'score': 0.022301768884062767},\n",
       " {'label': 'love', 'score': 0.9226101636886597},\n",
       " {'label': 'anger', 'score': 0.02163187973201275},\n",
       " {'label': 'fear', 'score': 0.01970757357776165},\n",
       " {'label': 'surprise', 'score': 0.003424924099817872}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_scores(\"im craving theres any other\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
